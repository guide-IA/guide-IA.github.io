<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link type="text/css" rel="stylesheet" href="style.css">
    <script src="https://kit.fontawesome.com/cb0e37a241.js" crossorigin="anonymous"></script>
    <title>Guide IA pour identifier, analyser des collections iconographiques et patrimoniales</title>
</head>

<body>
    <header><h1>Accueil du Guide IA dans les institutions patrimoniales</h1></header>
    <div class="flex">
        <section class="side">
            <ul>
                <li> <a href="index.html">Accueil</a></li>
                <li><a href="lexique.html">Lexique</a></li>
                <li><a href="exemples.html">Exemples de projets</a></li>
                <li><a href="applications.html">Outils, guides et applications.</a></li>
            </ul>
        </section>
        <section class="main">
            <h2 id="Début-du-guide">Début du guide</h2>

            <p> Ce guide de ressources a pour objectif de donner un premier aperçu et quelques conseils de bonnes pratiques, en
                particulier issues des expériences du consortium PictorIA sur la manière de traiter des données
                patrimoniales à l'aide d'outils IA. Dans le contexte de ce guide le terme IA recouvrira les technologies
                ayant recours au <i> machine-learning</i>. Ce guide ne traitera pas de formes d'IA tel que les forêts de
                décision ou les chaînes de Markov.</p>
            
            <p>Ce guide se concentrera sur les usages de l'IA dans le traitement des collections, la médiation, ou les usages dans l'administration du musée de l'IA n'étant pas les domaines d'étude des rédacteurs.</p>
            <h2> Principes de base</h2>
            <p>Avant d'entamer l'explication des usages identifiés de l'IA pour le traitement des collections, un court rappel sur quelques principes numériques qui s'appliquent également à l'IA.
                <ul><li>Tout d'abord, l'IA n'est pas une fin en soi. Nous devons insister sur le fait qu'elle est un outil, qui peut aider les personnels scientifiques des musées. Avant de déployer un système IA, il faut s'assurer de son intérêt pour la tâche qu'on veut réaliser. Il faut aussi noter que le coût d'entrée technique, financier ou matériel peut être élevé, et il faut évaluer l'avantage que le système IA peut apporter comparé à ce coût.</li>
                <li> Le fait de faire appel à un système IA ne dispense pas de l'exigence de scientificité d'un musée, les résultats des systèmes IA déployés doivent être évalués et évaluables, et s'ils sont suffisamment bons, documentés.</li>
                <li>De la même manière, faire appel à un système IA ne dispense pas des obligations légales du musée vis à vis des régimes de droit de ses collections. C'est d'autant plus vrai que certains protocoles communs vont faire appel à des serveurs extérieurs. Avant de lancer un processus, il faut se poser la question d'à qui on donne accès à quelles données, comme pour n'importe quel projet numérique.</li>
                <li>Enfin, de la même manière qu'elle a un coût technique et financier, l'IA a un coût écologie certain. Cette dimension ne doit pas être ignorée dans le calcul des coûts et bénéfices du déploiement d'un système IA.</li></ul>
            </p>

            <h2>1 - Description, indexation, classification et segmentation d'images</h2>
            <p>Cette section décrira les usages possibles de technologies IA pour améliorer la connaissance scientifique sur les collections. En préambule de cette section, il faut préciser que les technologies IA actuelles, et dans un futur proche n'ont absolument pas vocation à remplacer les personnels scientifiques des musées, ne serait-ce que parce que leur travail est absolument nécessaire pour entraîner, évaluer et contrôler les systèmes IA.
                En plus de cela, aucun <a href = "lexique.html#Modèle-IA"> modèle généraliste</a> n'est à ce jour capable de traiter de manière autonome et convaincante des collections patrimoniales, et l'entraînement de <a href = "lexique.html#Modèle-IA"> modèles spécialisés</a> requiert l'aide de spécialistes capables de produire et fournir des données d'entraînement de qualité. L'idée de cette section sera de proposer des outils, algorithmes et applications pour intégrer des éléments IA au travail sur les collections.</p>
            <p>Cette section s'appuiera principalement sur les travaux menés dans le cadre des projets <a href="exemples.html#torneh"> Torne-H</a>, <a href="exemples.html#hikaria">Hikaria</a>, <a href="exemples.html#VHS">VHS</a>, <a href="exemples.html#eida">Eida</a>, et des laboratoires d'archéologie AOrOc (UMR 8546) et Arscan (UMR 7041).</p>
            <p>Un usage efficace à mettre en place de l'IA observé dans ces travaux est d'abord la segmentation d'éléments dans des vues numérisées. Ci-dessous un exemple réalisé à l'aide d'un modèle Yolo : </p>
            <figure>
            <img src="https://cdn.prod.website-files.com/680a070c3b99253410dd3df5/684d85646cdaf7e5252b8497_67ed519cbf3f228c7bb790d7_67c99ff6c72a1cf68c554ff4_Segmentation_fig5.webp" alt="Des engins de chantiers detourés, auxquels sont apposés des étiquettes désignant le type de véhicule"><figcaption>Des engins de chantiers segmentés à l'aide d'un modèle yolo</figcaption></figure>
            
            <p>La segmentation peut servir, sur des corpus sériels, à  identifier les éléments représentés sur une images. Dans le cadre du projet Torne-H, un modèle de segmentation a par exemple été entraîné afin de déterminer quels types de meubles sont présents sur les dessins préparatoires de designers.
                Elle peut aussi par exemple servir de pré-traitement pour travailler sur des images contenues dans des ouvrages, ou dans d'autres images. On peut envisager ainsi de repérer les oeuvres dans des photographies d'exposition, dans des catalogues d'exposition, ou encore des manuscrits, comme ça a été le cas pour les projets EIDA et VHS. </p>
            <p> Les principales familles de modèles de segmentation sont les modèles YOLO, ou DINO, qui associe une "classe" à des parties de l'image, ou les modèles SAM, capables de découper les images en fonction des traits et de caractéristiques visuelles.</p>

            <p>Les modèles de classification vont, comme leur nom l'indique, associer une image à une "classe". Contrairement aux modèles de segmentation, qui peuvent, pour certains associer des classes à une partie de l'image, les modèles de classification associent une classe à l'intégralité de l'image. 
               Ce type de modèle sera particulièrement intéressant sur un nombre limité de classe. On peut par exemple facilement envisager des traitements qui sépareraient les images sur un niveau de description "bas", comme c'est le cas dans l'image ci-dessous, ou à l'aide de modèles spécialisés sur des corpus déjà triés. C'est par exemple ce qui a pu être fait sur des motifs de tessons de poterie.
                Il faut plus généralement retenir le principe que plus on demandera de classes différentes à un modèle, moins il sera précis pour un entraînement équivalent.</p>
                <figure>
                    <img src = "classification3.png" alt="un schéma représentant le fonctionnement d'un modèle classifiant des tableaux en 4 catégories, nature morte, paysage, portrait et scènes"><figcaption>Représentation d'un modèle entraîné par Pierre Husson au service numérique de la recherche de l'INHA. Le modèle détermine si le tableau est un portrait, une nature morte, un paysage, les autres tableaux sont rassemblés sous le titre fourre-tout de "scène".</figcaption>
                </figure>
              <p>  La classification est utile pour catégoriser des images sur des corpus massifs mais relativement homogènes. En l'état ces modèles ne sont pas fiables sur un trop grand nombre de classes, mais fonctionnels sur un petit nombre. Comme la segmentation, les modèles de types Yolo ou Dino peuvent réaliser des classifications. On peut également utiliser certains modèles de <a href="lexique.html#LLM">VLM/LLM</a>, comme Florence, ou Qwen pour ces tâches, mais obtenir des sorties structurées et controlables de ces modèles demande un travail plus fin.  </p>
            <p>La description et l'indexation d'images sont deux objets problématiques loin d'être résolus au moment d'écriture de ce guide. La description est envisageable avec des modèles type VLM, mais pose le problème fondamental de la mesurabilité des résultats. L'indexation sur plusieurs niveaux à l'aide de thésaurus complexes comme le thésaurus Garnier pose un problème différent, qui est l'inadaptation des modèles d'IA contemporrains à ces plusieurs niveau d'indexation. 
                On peut envisager un traitement par plusieurs modèles de classification pour imiter les différents niveaux d'un thésaurus, mais il faut noter que la multiplication des traitements multiplie le nombre d'erreurs, et chaque entraînement a un cout technique et écologique qui doit être pris en compte. Pour ces deux usages, s'il ne faut pas exclure les traitement entièrement automatisés, sur des quantités raisonnables d'images nous recommanderions plutôt d'avoir recours à l'IA pour appuyer le personnel scientifique, dans le cadre de traitements semi automatiques, comme décrit dans le partie 3 (insérer lien) de ce guide.
             </p>
            <h2>Reconnaissance et transcription de textes imprimés et manuscrits</h2>
            <p>Cette section décrira les usages possibles de technologies IA pour automatiser la reconnaissance de caractères dans des documents numérisés. L'OCR (Optical Character Recognition) et l'HTR (Handwritten Text Recognition) sont des technologies qui ont beaucoup évolués ces dernières années grâce aux progrès de l'IA, et en particulier du <a href="lexique.html#Deep-learning"> deep learning</a>. De nombreux outils et applications sont désormais disponibles pour automatiser la reconnaissance de caractères dans des documents imprimés ou manuscrits, avec des niveaux de performance très élevés. </p>
            <h3>Tour d'horizon rapide</h3>
                <p>Ce sont des technologies plus anciennes et plus éprouvées que celles de vision par ordinateur ou d'IA génératives et elles se séparent donc en deux grandes catégories : l'OCR et l'HTR.
                Concernant l'HTR nous pouvons citer des outils comme <a href="applications.html#kraken">Kraken</a> qui offrent une solution complète de l'installation, aux premiers travaux de reconnaissances jusqu'au ré-entrainement pour <a href="lexique.html#Finetuning">fine-tuning</a> et l'export massif.</p>
                <p>Ou bien des solutions comme <a href="applications.html#transkribus">Transkribus</a> ou <a href="applications.html#escriptorium">eScriptorium</a> proposent des interfaces utilisateurs et des performances élevées.</p>
                <p>Ensuite, pour l'OCR beaucoup d'outils existent mais nous mentionnons l'existence de deux projets performants <a href="applications.html#peroocr">PeroOCR</a> et <a href="applications.html#tesseract">Tesseract</a> qui offrent des bons résultats complètement gratuitements</p>
            <img src = "HTR_Calfa_BnF.png" alt="capture d'écran montrant un résultat d'HTR sur des textes arabes manuscrits">

            <h3>Mise en place</h3>
                <p>La mise en place de ces technologies dépendra de vos besoins, de vos compétences techniques et de vos ressources matérielles. Pour des besoins ponctuels ou des volumes limités, des solutions en ligne comme Transkribus peuvent être suffisantes. Pour des besoins plus importants ou des exigences spécifiques, l'installation locale de Kraken ou Tesseract peut être nécessaire.</p>
                <p>Il est important de noter que la qualité des résultats dépendra fortement de la qualité des images numérisées et de la spécificité des documents (langue, écriture, mise en page). Dans certains cas, un ré-entrainement du modèle peut être nécessaire pour obtenir des résultats satisfaisants.</p>
                <p>En terme d'infrastructures des <a href="lexique.html#GPU">GPU</a> risquent d'être nécessaires pour les larges corpus (au-delà de 1000 pages). Pour les moyens humains, il faut avoir en tête qu'avoir une personne qui parle la langue, ou lit l'écriture du siècle en question est souvent indispensable pour le réentrainement. Du côté technique, les applications ne sont pas excessivement compliquées et elles sont bien documentées, mais leur manipulation requiert un minimum d'aisance avec l'informatique.</p>
            <img src ="OCR_Hugo_BnF.png" alt="capture d'écran montrant un résultat d'un OCR sur un texte de Victor Hugo">
                    <h2> Et les LLMs génératifs dans tout ça ?</h2>
                    <p>Lorem ipsum etc etc</p>
        </section>
        <section><p> Ce guide est destiné à des personnes ayant des niveaux informatiques variables, et est pensé pour n'avoir aucun prérequis technique d'entrée, si certains termes vous sont étrangers n'hésitez pas à consulter notre lexique.
            Du fait de l'évolution très rapide des technologies dans ce secteur certains des projets et certaines des applications présentées dans ce guide peuvent être obsolètes au moment de la lecture.
            En introduction de ce guide nous voulons également insister sur le fait que l'"IA" ne doit pas être une fin en soi, et devrait être utilisée comme un outil pour accomplir une mission.
            A ce titre, des questions telles que le régime de droit des données traitées, le coût économique, écologique ou l'accompagnement au changement doivent être réflechies de la même manière que pour n'importe quel outil numérique.</p>
        </section>

    </div>
</body>

</html>